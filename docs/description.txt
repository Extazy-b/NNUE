Я занимаюсь разработкой и обучением специализированной NNUE-сети для шахматного движка с целью получить рабочий MVP, который можно интегрировать в движок за один месяц в рамках летней практики. Параллельно исследую возможную адаптацию архитектуры NNUE для задач биоинформатики (предсказание структуры РНК, белковое взаимодействие), но текущий приоритет — работоспособный и оптимизированный для CPU inference NNUE для шахматного движка.

Цель MVP: от FEN до оценки позиции. Технический поток: FEN → индексы признаков (STM, SnTM) → forward (аккумулятор + CReLU + выходной слой) → обучение в PyTorch → пост-тренировочная квантизация в int16 → экспорт весов + мета → C++ inference с int16 весами и int32 аккумуляцией. Ключевые ограничения: вход бинарный и разреженный (N = 40960 возможных комбинаций), размер аккумулятора M ≈ 256, веса в итоговой системе — int16, аккумулирование и промежуточные суммы — int32, активация — clipped ReLU (порог t, обычно 127).

Текущий стек и роли:

Прототип и тренировка: Python 3 + PyTorch. Быстрая итерация, автоград, DataLoader. Использовать PyTorch для возможного QAT при необходимости.

Экспорт/квантование: Python-скрипты для пост-тренировочного квантования, сохранения QA/QB и мета.

Inference: C++17 библиотека для интеграции в движок. Однопозиционный evaluate(fen) как минимальный API, с последующей опцией SIMD-оптимизаций (AVX2), но сначала scalar/portable путь.

Инструменты: numpy, simple CLI-скрипты, unit-tests на Python (pytest) и тесты C++ (googletest) для валидации численной идентичности.

Краткое описание архитектуры репозитория (минимум для MVP): папки data/raw и data/processed, src/python (dataset.py, model.py, train.py, quantize.py), src/cpp (nnue.hpp, nnue.cpp, example.cpp), tests/ (test_incremental.py, test_forward.py), models/exported.bin и models/meta.json. Формат экспорта: бинарный файл с заголовком (magic, M, N, t, QA, QB, layout, git-hash, timestamp) и последовательными массивами A1(int16), A2(int16), B1(int32), B2(int32), C(int16), d(int32). Рядом хранить человекочитаемый meta.json с тем же набором полей.

Ключевые требования к реализации:

Dataset: FEN → два массива индексов (STM, SnTM) для каждого примера; батч строится как список списков индексов. Формат батча на этапе тренировки — numpy/npz с X1_idx, X2_idx, y.

Model (Python): аккумулирование sum(A[:, idxs]) для каждого примера, добавление bias, конкатенация STM/SnTM, CReLU clamp, умножение на C → скалярная оценка. Потеря — MSE; оптимизатор — AdamW или SGD (рекомендация: AdamW, LR ~1e-3, batch size 32–256 в зависимости от RAM).

Квантование: для MVP использовать post-training quantization. Вычислить масштаб QA для A-матриц и QB для выходного слоя, округлить веса до int16, хранить QA/QB в meta. Аккумуляция в int32, масштабирование результата обратно с учётом QA*QB.

Inference (C++): загрузчик экспортного bin, single-position evaluate(fen) строит индексы и выполняет int32 accumulation, clamp, int32 multiply-add с C, финальная нормализация. Провести сравнение с float-референсом.

Тесты: тест корректности инкрементального обновления (инкрементал == полное пересчёты), тест совпадения float-reference vs quantized C++ с допуском по MSE. Автоматические unit-тесты в CI.

Критические риски и как их уменьшить:

Деградация после квантизации — сначала PTQ; если ошибка большая, добавить QAT за счёт 1–2 дополнительных дней. Всегда сравнивать на валидации до/после.

Переполнение при аккумулировании — аккумулировать в int32, добавлять защитные clamping и тесты.

Производительность SIMD — сначала реализовать корректный scalar путь; оптимизации по SIMD выделять как отдельный шаг после валидации корректности.

Ожидаемые конкретные артефакты к дедлайну:

Рабочий Python-пайплайн: dataset loader, модель, train.py, checkpoint.

Скрипт quantize.py и экспортный бинарный файл models/exported.bin + meta.json.

Минимальный C++ inference модуль (nnue.hpp/nnue.cpp) с примером использования example.cpp.

Набор unit-тестов: тесты корректности forward и инкрементального обновления.

Краткая инструкция по сборке и интеграции (README, команды сборки C++).

Приоритеты задач (в порядке выполнения): 1) dataset + reference forward в Python; 2) простой training loop и sanity-check на маленьком датасете; 3) экспорт и PTQ; 4) C++ loader + single-position inference; 5) unit-tests и сравнения; 6) оптимизации и QAT при наличии времени.

Метрики оценки успеха MVP: сходство quantized inference с float-reference по MSE (порог зависит от данных, ориентир: минимальный влияющий на сильные отличия в оценке; практический порог — определять на валидации), скорость оценки одной позиции (латентность) и память (размер экспортированного файла). Для шахматного применения важна детерминированность и стабильность оценок при смене позиций.